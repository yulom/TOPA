{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26131c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Conda\\envs\\eegenvs\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "gpus = [0]\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(map(str, gpus))\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "import math\n",
    "from model_utils import SSA, LightweightConv1d, Mixer1D\n",
    "from TOPA import TOPA_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c254ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#network architecture modified fromï¼šSST-DPN https://github.com/hancan16/SST-DPN\n",
    "class Efficient_Encoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        samples,\n",
    "        chans,\n",
    "        F1=16,\n",
    "        F2=36,\n",
    "        time_kernel1=75,\n",
    "        pool_kernels=[50, 100, 250],\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time_conv = LightweightConv1d(\n",
    "            in_channels=chans,\n",
    "            num_heads=1,\n",
    "            depth_multiplier=F1,\n",
    "            kernel_size=time_kernel1,\n",
    "            stride=1,\n",
    "            padding=\"same\",\n",
    "            bias=True,\n",
    "            weight_softmax=False,\n",
    "        )\n",
    "        self.ssa = SSA(samples, chans * F1)\n",
    "\n",
    "        self.chanConv=nn.Conv1d(\n",
    "                chans * F1,\n",
    "                F2,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            )\n",
    "        self.batchNorm1d = nn.BatchNorm1d(F2)\n",
    "        self.dBatchNorm1d = []\n",
    "        for i in range(9):\n",
    "            self.dBatchNorm1d += [nn.BatchNorm1d(F2).cuda()]\n",
    "        self.elu = nn.ELU()\n",
    "\n",
    "        self.mixer = Mixer1D(dim=F2, kernel_sizes=pool_kernels)\n",
    "\n",
    "    def forward(self, x,x_domain=None,dBatchNorm=False):\n",
    "\n",
    "        x = self.time_conv(x)\n",
    "        # print(x.shape)\n",
    "        x, _ = self.ssa(x)\n",
    "        # print(x.shape)\n",
    "        x_chan = self.chanConv(x)\n",
    "        if dBatchNorm:\n",
    "            y = torch.zeros_like(x_chan)\n",
    "            for i in x_domain.unique():\n",
    "                x_ = x_chan[x_domain==i]\n",
    "                # print(x_.shape)\n",
    "                y[x_domain==i] = self.dBatchNorm1d[i-1](x_)\n",
    "            x_chan = self.elu(y)\n",
    "        else:\n",
    "            x_chan = self.batchNorm1d(x_chan)\n",
    "        # print(x_chan.shape)\n",
    "        feature = self.mixer(x_chan)\n",
    "        # print(feature.shape)\n",
    "\n",
    "        # feature = self.linear(feature)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class EEGEncoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        chans,\n",
    "        samples,\n",
    "        num_classes=4,\n",
    "        F1=9,\n",
    "        F2=48,\n",
    "        time_kernel1=75,\n",
    "        pool_kernels=[50, 100, 200],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = Efficient_Encoder(\n",
    "            samples=samples,\n",
    "            chans=chans,\n",
    "            F1=F1,\n",
    "            F2=F2,\n",
    "            time_kernel1=time_kernel1,\n",
    "            pool_kernels=pool_kernels,\n",
    "        )\n",
    "        self.features = None\n",
    "\n",
    "        x = torch.ones((1, chans, samples))\n",
    "        out = self.encoder(x)\n",
    "        feat_dim = out.shape[-1]\n",
    "        \n",
    "        class ClassifyHead(nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.isp = nn.Parameter(torch.randn(num_classes, feat_dim), requires_grad=True)\n",
    "                nn.init.kaiming_normal_(self.isp)\n",
    "            def forward(self,x,wog = False):\n",
    "                if wog:\n",
    "                    return -torch.cdist(x, self.isp.detach(), p=2)\n",
    "                else:\n",
    "                    return -torch.cdist(x, self.isp, p=2)\n",
    "                # return torch.einsum(\"bd,cd->bc\", x, self.isp)\n",
    "        self.classifyHead = ClassifyHead()\n",
    "\n",
    "    def get_features(self):\n",
    "        if self.features is not None:\n",
    "            return self.features\n",
    "        else:\n",
    "            raise RuntimeError(\"No features available. Run forward() first.\")\n",
    "\n",
    "    def forward(self, x,x_domain):\n",
    "\n",
    "        features = self.encoder(x,x_domain,dBatchNorm=True)\n",
    "        self.features = features\n",
    "        logits = self.classifyHead(features,wog=False)\n",
    "\n",
    "        return logits,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371e83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLExP():\n",
    "    def __init__(self, trainSetI,testSetI):\n",
    "        super(TLExP, self).__init__()\n",
    "        self.batch_size = 72*2\n",
    "        self.n_epochs = 2000\n",
    "        self.c_dim = 4\n",
    "        self.lr = 0.0002\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.trainSetI = trainSetI\n",
    "        self.testSetI = testSetI\n",
    "        self.targetDomainLabel = eval(testSetI[0][0])\n",
    "        seti = [testSetI[0][0],]\n",
    "        for i in trainSetI:\n",
    "            seti.append(i[0])\n",
    "        self.SetIs = set(seti)\n",
    "        self.trainNum = len(self.SetIs)\n",
    "\n",
    "        self.start_epoch = 0\n",
    "        self.root = 'D:\\Projects\\DataSet\\standard_2a_data/'\n",
    "\n",
    "        trainIs = \"\"\n",
    "        for i in trainSetI:\n",
    "            trainIs = trainIs+i\n",
    "\n",
    "        self.Tensor = torch.cuda.FloatTensor\n",
    "        self.LongTensor = torch.cuda.LongTensor\n",
    "\n",
    "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.model = EEGEncoder(chans=22, samples=1000, num_classes=4).cuda()\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "    def interaug_TL(self, timg, label):  \n",
    "        aug_data = []\n",
    "        aug_label = []\n",
    "\n",
    "        for cls0 in torch.unique(label[:,0]):\n",
    "            for cls1 in torch.unique(label[:,1]):\n",
    "                conbinedCls = torch.tensor((cls0,cls1))\n",
    "                cls_idx0 = np.where(label[:,0] == conbinedCls[0])\n",
    "                cls_idx1 = np.where(label[:,1] == conbinedCls[1])\n",
    "                cls_idx=np.intersect1d(cls_idx0,cls_idx1)\n",
    "                #print(cls_idx)\n",
    "                tmp_data = timg[cls_idx]\n",
    "                tmp_label = label[cls_idx,:]\n",
    "                tmp_aug_data = np.zeros((int(self.batch_size / (len(torch.unique(label[:,0]))*len(torch.unique(label[:,1])))),22, 1000))\n",
    "                for ri in range(int(self.batch_size / (len(torch.unique(label[:,0]))*len(torch.unique(label[:,1]))))):\n",
    "                    for rj in range(8):\n",
    "                        rand_idx = np.random.randint(0, tmp_data.shape[0], 8)\n",
    "                        tmp_aug_data[ri, :, rj * 125:(rj + 1) * 125] = tmp_data[rand_idx[rj], :,\n",
    "                                                                      rj * 125:(rj + 1) * 125]\n",
    "                aug_data.append(tmp_aug_data)\n",
    "                aug_label.append(tmp_label[0,:].repeat(tmp_aug_data.shape[0],1))\n",
    "\n",
    "        aug_data = np.concatenate(aug_data)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        aug_shuffle = np.random.permutation(len(aug_data))\n",
    "        aug_data = aug_data[aug_shuffle, :, :]\n",
    "        aug_label = aug_label[aug_shuffle]\n",
    "\n",
    "        aug_data = torch.from_numpy(aug_data).cuda()\n",
    "        aug_data = aug_data.float()\n",
    "        aug_label = torch.from_numpy(aug_label).cuda()\n",
    "        aug_label = aug_label.long()\n",
    "        aug_label[:,0] = aug_label[:,0]\n",
    "        return aug_data, aug_label\n",
    "\n",
    "    def get_source_data(self,keep_ratio=0.8):\n",
    "        filename = self.trainSetI[0]\n",
    "        print('load train data...')\n",
    "        for i in range(len(self.trainSetI)):\n",
    "            filename = self.trainSetI[i]\n",
    "            total_data = scipy.io.loadmat(self.root + 'rawA0'+filename+'.mat')\n",
    "            if i==0:\n",
    "                train_data = total_data['data']\n",
    "                train_label = total_data['label']\n",
    "                train_seti = np.full_like(total_data['label'],eval(filename[0]))\n",
    "            else:\n",
    "                train_data = np.concatenate((train_data,total_data['data']),axis=2)\n",
    "                train_label = np.concatenate((train_label,total_data['label']))\n",
    "                train_seti = np.concatenate((train_seti,np.full_like(total_data['label'],eval(filename[0]))))\n",
    "        print('load test data...')\n",
    "        for i in range(len(self.testSetI)):\n",
    "            filename = self.testSetI[i]\n",
    "            total_data = scipy.io.loadmat(self.root + 'rawA0'+filename+'.mat')\n",
    "            if i==0:\n",
    "                test_data = total_data['data']\n",
    "                test_label = total_data['label']\n",
    "                test_seti = np.full_like(total_data['label'],eval(filename[0]))\n",
    "            else:\n",
    "                test_data = np.concatenate((test_data,total_data['data']),axis=2)\n",
    "                test_label = np.concatenate((test_label,total_data['label']))\n",
    "                test_seti = np.concatenate((test_seti,np.full_like(total_data['label'],eval(filename[0]))))\n",
    "\n",
    "        test_data = np.transpose(test_data, (2, 1, 0))\n",
    "        train_data = np.transpose(train_data, (2, 1, 0))\n",
    "        train_label = np.transpose(train_label[:,0])\n",
    "        train_seti = np.transpose(train_seti[:,0])\n",
    "        test_label = np.transpose(test_label[:,0])\n",
    "        test_seti = np.transpose(test_seti[:,0])\n",
    "        print('data load finished')\n",
    "        return train_data,train_label,train_seti,test_data,test_label,test_seti\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.train_data, self.train_label, self.train_seti, self.test_data, self.test_label, self.test_seti = self.get_source_data()\n",
    "        \n",
    "        train_data = torch.from_numpy(self.train_data)\n",
    "        train_label = torch.from_numpy(self.train_label - 1)\n",
    "        train_seti = torch.from_numpy(self.train_seti)\n",
    "        self.train_data = train_data\n",
    "        self.train_label = torch.stack((train_label,train_seti),dim=1)\n",
    "        rand_index = torch.randperm(self.train_label.size(0))\n",
    "        val_ratio = 0.125\n",
    "        val_index = int(self.train_label.size(0)*val_ratio)\n",
    "        self.val_data = self.train_data[rand_index[:val_index]]\n",
    "        self.val_label = self.train_label[rand_index[:val_index]]\n",
    "        self.train_data = self.train_data[rand_index[val_index:]]\n",
    "        self.train_label = self.train_label[rand_index[val_index:]]\n",
    "        dataset = torch.utils.data.TensorDataset(self.train_data, self.train_label)\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        test_data = torch.from_numpy(self.test_data)\n",
    "        test_label = torch.from_numpy(self.test_label - 1)\n",
    "        test_seti = torch.from_numpy(self.test_seti)\n",
    "        \n",
    "        self.test_data = test_data\n",
    "        self.test_label =torch.stack((test_label,test_seti),dim=1)\n",
    "        test_dataset = torch.utils.data.TensorDataset(self.test_data,self.test_label)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size*2, shuffle=True)\n",
    "        isp_params = self.model.classifyHead.isp\n",
    "        \n",
    "        other_params = [param for name, param in self.model.named_parameters() if name != 'classifyHead.isp']\n",
    "        \n",
    "        self.optimizer_isp = torch.optim.Adam([isp_params], lr=self.lr*10, betas=(self.b1, self.b2))\n",
    "        self.optimizer_other = torch.optim.Adam(other_params, lr=self.lr, betas=(self.b1, self.b2))\n",
    "\n",
    "        test_data = Variable(test_data.type(self.Tensor))\n",
    "        test_label = Variable(torch.stack((test_label,test_seti),dim=1).type(self.LongTensor))\n",
    "        \n",
    "        self.val_data = Variable(self.val_data.type(self.Tensor))\n",
    "        self.val_label = Variable(self.val_label.type(self.LongTensor))\n",
    "\n",
    "        bestAcc = 0\n",
    "        bestAcc_val = 0\n",
    "        finalAcc = 0\n",
    "        averAcc = 0\n",
    "        num = 0\n",
    "        Y_true = 0\n",
    "        Y_pred = 0\n",
    "\n",
    "\n",
    "        self.mcc_ratio = 0.\n",
    "        for e in range(self.n_epochs):\n",
    "            self.model.train()\n",
    "            \n",
    "            for ee in range(8):\n",
    "                s_img,s_label = next(iter(self.dataloader))\n",
    "                s_img = Variable(s_img.cuda().type(self.Tensor))\n",
    "                s_label = Variable(s_label.cuda().type(self.LongTensor))\n",
    "                aug_img,aug_label = self.interaug_TL(self.train_data, self.train_label)\n",
    "                s_img = torch.cat((s_img,aug_img))\n",
    "                s_label = torch.cat((s_label,aug_label))\n",
    "                t_img,t_label = next(iter(self.test_dataloader))\n",
    "                t_img = Variable(t_img.cuda().type(self.Tensor))\n",
    "                t_label = Variable(t_label.cuda().type(self.LongTensor))\n",
    "                minlen = min(s_img.shape[0],t_img.shape[0])\n",
    "                s_img = s_img[:minlen,:,:]\n",
    "                s_label = s_label[:minlen,:]\n",
    "                t_img = t_img[:minlen,:,:]\n",
    "                t_label = t_label[:minlen,:]\n",
    "                img = torch.cat((s_img.cuda(),t_img.cuda()))\n",
    "                label= torch.cat((s_label.cuda(),t_label.cuda()))\n",
    "                domains = label[:,1]\n",
    "                outputs,feature = self.model(img,domains)\n",
    "                y_s, y_t = outputs.chunk(2, dim=0)\n",
    "\n",
    "                \n",
    "                features_s, features_t = feature.chunk(2, dim=0)\n",
    "                classfyout = y_s\n",
    "                trainlabel = s_label\n",
    "\n",
    "                cls_loss = self.criterion_cls(classfyout, s_label[:,0]) \n",
    "\n",
    "                topa_loss = TOPA_Loss(y_t,self.model.classifyHead.isp.T)\n",
    "                self.topa_ratio = 1-np.exp(1*e/(e-self.n_epochs+1e-9))\n",
    "                loss = cls_loss + 1*self.topa_ratio*topa_loss \n",
    "\n",
    "                self.optimizer_isp.zero_grad()\n",
    "                self.optimizer_other.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer_isp.step()\n",
    "                self.optimizer_other.step()\n",
    "\n",
    "            if (e + 1) % 1 == 0:\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    Cls,_ = self.model(test_data, test_label[:,1])\n",
    "    \n",
    "                    loss_test = self.criterion_cls(Cls, test_label[:,0])\n",
    "                    y_pred = torch.max(Cls, 1)[1]\n",
    "                    acc = float((y_pred == test_label[:,0]).cpu().numpy().astype(int).sum()) / float(test_label[:,0].size(0))\n",
    "\n",
    "                    train_pred = torch.max(classfyout, 1)[1]\n",
    "                    train_acc = float((train_pred == trainlabel[:,0]).cpu().numpy().astype(int).sum()) / float(trainlabel[:,0].size(0))\n",
    "\n",
    "                    Cls,_ = self.model(self.val_data, self.val_label[:,1])\n",
    "    \n",
    "                    loss_val = self.criterion_cls(Cls, self.val_label[:,0])\n",
    "                    y_pred = torch.max(Cls, 1)[1]\n",
    "                    acc_val = float((y_pred == self.val_label[:,0]).cpu().numpy().astype(int).sum()) / float(self.val_label[:,0].size(0))\n",
    "                    \n",
    "                    print('Epoch:', e,\n",
    "                          '  Train loss: %.6f' % loss.detach().cpu().numpy(),\n",
    "                          '  TOPA_loss: %.6f' % topa_loss.detach().cpu().numpy(),\n",
    "                          '  cls_loss: %.6f' % cls_loss.detach().cpu().numpy(),\n",
    "                          '  Test loss: %.6f' % loss_test.detach().cpu().numpy(),\n",
    "                          '  Train accuracy %.6f' % train_acc,\n",
    "                          '  val accuracy is %.6f' % acc_val,\n",
    "                          '  Test accuracy is %.6f' % acc)\n",
    "    \n",
    "                    num = num + 1\n",
    "                    averAcc = averAcc + acc\n",
    "                    if acc > bestAcc:\n",
    "                        bestAcc = acc\n",
    "                    if acc_val > bestAcc_val:\n",
    "                        finalAcc = acc\n",
    "                        bestAcc_val = acc_val\n",
    "                        # torch.save(self.model.state_dict(), 'ckpt/edpnet_'+self.testSetI[0]+'.pth')\n",
    "                        print('best!')\n",
    "        averAcc = averAcc / num\n",
    "        print('The average accuracy is:', averAcc)\n",
    "        print('The test accuracy is:', finalAcc)\n",
    "        print('The last accuracy is:', acc)\n",
    "        print('The best accuracy is:', bestAcc)\n",
    "        # torch.save(self.model.state_dict(), 'ckpt/edpnet_last_'+self.testSetI[0]+'.pth')\n",
    "\n",
    "        return bestAcc, averAcc, Y_true, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load train data...\n",
      "load test data...\n",
      "data load finished\n",
      "Epoch: 0   Train loss: 1.381169   TOPA_loss: 13.408327   cls_loss: 1.381169   Test loss: 1.382989   Train accuracy 0.261029   val accuracy is 0.284722   Test accuracy is 0.256944\n",
      "best!\n"
     ]
    }
   ],
   "source": [
    "trainSetI = ['2T','3T','4T','5T','6T','7T','8T','9T']\n",
    "testSetI = ['1E']\n",
    "exp = TLExP(trainSetI,testSetI)\n",
    "bestAcc, averAcc, Y_true, Y_pred= exp.train()\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1c011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegenvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
